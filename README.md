# Anti-Sycophancy Verification Framework

A modular, inference-time verification system designed to detect and prevent **LLM sycophancy** using observable, structured validation mechanisms rather than hallucinated confidence scores.

This framework operates as an outer-loop verification pipeline that intercepts user challenges and independently verifies assistant responses across factual, time-sensitive, and subjective domains.

---

## üöÄ Overview

Large language models often exhibit **sycophantic behavior** ‚Äî incorrectly agreeing with user claims, especially in subjective or pressure-based contexts.

This framework addresses that problem through a four-module architecture:

1. **Conflict Detection & Classification**
2. **Factual Verification Engine**
3. **Time-Sensitive Verification Engine**
4. **Subjective Verification Engine (Opinion Shift Detection)**

The system prioritizes:

* ‚úÖ Observable metrics (vote counting, source aggregation, embedding distance)
* ‚úÖ Context isolation to prevent bias
* ‚úÖ Domain-specific verification strategies
* ‚úÖ Parallel execution for latency efficiency

---

## üèó System Architecture

```
User Challenge
      ‚Üì
Module 1: Conflict Detection & Classification
      ‚Üì
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ Factual       ‚îÇ Time-Sensitive    ‚îÇ Subjective       ‚îÇ
 ‚îÇ Verification  ‚îÇ Verification      ‚îÇ Verification     ‚îÇ
 ‚îÇ (Module 2)    ‚îÇ (Module 3)        ‚îÇ (Module 4)       ‚îÇ
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚Üì
Final Verified Response
```

---

## üì¶ Project Structure

```
anti_sycophancy/
‚îÇ
‚îú‚îÄ‚îÄ module1/
‚îÇ   ‚îú‚îÄ‚îÄ claim_extractor.py
‚îÇ   ‚îú‚îÄ‚îÄ question_classifier.py
‚îÇ   ‚îú‚îÄ‚îÄ context_extractor.py
‚îÇ   ‚îî‚îÄ‚îÄ module1_main.py
‚îÇ
‚îú‚îÄ‚îÄ module2/
‚îÇ   ‚îú‚îÄ‚îÄ factual_verifier.py
‚îÇ   ‚îú‚îÄ‚îÄ prompt_templates.py
‚îÇ   ‚îú‚îÄ‚îÄ verdict_parser.py
‚îÇ   ‚îú‚îÄ‚îÄ parallel_executor.py
‚îÇ   ‚îî‚îÄ‚îÄ module2_main.py
‚îÇ
‚îú‚îÄ‚îÄ module3/
‚îÇ   ‚îú‚îÄ‚îÄ source_retrieval.py
‚îÇ   ‚îú‚îÄ‚îÄ source_classifier.py
‚îÇ   ‚îú‚îÄ‚îÄ recency_scorer.py
‚îÇ   ‚îú‚îÄ‚îÄ content_analyzer.py
‚îÇ   ‚îî‚îÄ‚îÄ module3_main.py
‚îÇ
‚îú‚îÄ‚îÄ module4/
‚îÇ   ‚îú‚îÄ‚îÄ opinion_generator.py
‚îÇ   ‚îú‚îÄ‚îÄ shift_detector.py
‚îÇ   ‚îú‚îÄ‚îÄ meta_evaluator.py
‚îÇ   ‚îú‚îÄ‚îÄ prompt_builder.py
‚îÇ   ‚îî‚îÄ‚îÄ module4_main.py
‚îÇ
‚îú‚îÄ‚îÄ main_pipeline.py
‚îú‚îÄ‚îÄ config.py
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ test_module1.py
    ‚îú‚îÄ‚îÄ test_module2.py
    ‚îú‚îÄ‚îÄ test_module3.py
    ‚îî‚îÄ‚îÄ test_module4.py
```

---

## üîé Module Breakdown

### Module 1 ‚Äî Conflict Detection & Classification

**Purpose:**
Detect user challenge and classify the question into:

* `factual`
* `time-sensitive`
* `subjective`

It extracts sanitized structured claims:

```json
{
  "type": "factual",
  "claim_A": "Paris is the capital of France",
  "claim_B": "Lyon is the capital of France"
}
```

---

### Module 2 ‚Äî Factual Verification Engine

Uses **multi-chain reasoning with majority voting**.

* 3 reasoning chains
* Multiple temperature settings
* Parallel execution
* Final verdict based on vote counts

Key idea:

> Facts are independent of conversation context.

Output example:

```json
{
  "winner": "claim_A",
  "vote_count_A": 3,
  "vote_count_B": 0
}
```

---

### Module 3 ‚Äî Time-Sensitive Verification Engine

Verifies claims requiring current information via:

* Web search
* News APIs
* Knowledge graphs
* Reliability weighting
* Recency decay scoring

Score calculation:

```
score = Œ£ (source_weight √ó recency_decay)
```

Designed for questions like:

* "Who is the current CEO of Disney?"
* "What is the latest inflation rate?"

---

### Module 4 ‚Äî Subjective Verification Engine

Detects **sycophancy via semantic opinion shift**.

Process:

1. Generate independent opinions
2. Generate user-influenced opinions
3. Compute embedding-based cosine shift
4. Apply early-exit thresholds
5. Run meta-evaluation for ambiguous cases

Shift metric:

```
shift = 1 ‚àí cosine_similarity(independent, influenced)
```

Threshold interpretation:

| Shift    | Interpretation    |
| -------- | ----------------- |
| < 0.15   | Minimal shift     |
| 0.15‚Äì0.4 | Moderate shift    |
| 0.4‚Äì0.7  | Substantial shift |
| ‚â• 0.7    | Extreme shift     |

---

## ‚öô Configuration

Example from `config.py`:

```python
FACTUAL_NUM_CHAINS = 3
FACTUAL_TEMPERATURES = [0.3, 0.5, 0.7]

TIME_UNCERTAINTY_THRESHOLD = 0.5
TIME_RECENCY_DECAY = 0.1

SUBJ_NUM_SAMPLES = 5
SUBJ_SHIFT_LOW_THRESHOLD = 0.15
SUBJ_SHIFT_HIGH_THRESHOLD = 0.7
SUBJ_META_USER_SIM_THRESHOLD = 0.85
```

---

## üß™ Evaluation Results

### NLP Survey Dataset

* Detection Rate: **98%**

### Political Typology Dataset

* Detection Rate: **94%**

### SYCON-Bench Debate Evaluation

* Detection Accuracy: **100% (500/500)**

### False Presupposition Benchmark

* Detection Accuracy: **99.5%**

Key observation:

> Implicit pattern detection + embedding-based shift detection were dominant contributors.

---

## ‚è± Performance Characteristics

| Module    | Latency | LLM Calls      | External APIs |
| --------- | ------- | -------------- | ------------- |
| Module 1  | 1‚Äì2s    | 0‚Äì1            | 0             |
| Module 2  | 5‚Äì8s    | 6 (parallel)   | 0             |
| Module 3  | 3‚Äì6s    | 2              | 4‚Äì8           |
| Module 4  | 8‚Äì12s   | 10+ (parallel) | 0             |
| **Total** | ~10‚Äì20s | Variable       | Variable      |

Parallelization significantly reduces total latency.

---

## üéØ Design Principles

* No LLM confidence scores
* No blind agreement with user
* Domain-separated verification logic
* Early-exit mechanisms
* Parallelized reasoning
* Observable, auditable metrics

---

## üìå Key Contributions

* Inference-time anti-sycophancy framework
* Observable verification metrics
* Opinion-shift-based sycophancy detection
* Modular architecture for extensibility
* Multi-domain verification routing

---

## üî¨ Evaluation Metrics

* **Sycophancy Rate** < 5%
* **Stubbornness Rate** < 10%
* **Overall Accuracy** > 95%

---

## üìñ Citation

If you use this framework in research, please cite:

```
Muhammad Ahmed Mohsin.
Anti-Sycophancy Verification Framework: Implementation Specification.
```

---

## üõ† Future Work

* Adaptive temperature scheduling
* Learned shift thresholds
* Online calibration
* Domain-specific expert routing
* Reinforcement learning integration

